---
title: 'Data Science: Wrangling - Assessments'
author: "Hector Antigua"
date: "Last compiled on `r format(Sys.time(), '%B, %Y')`"
output: word_document



---

```{r,include = FALSE}
options(repos = list(CRAN="http://cran.rstudio.com/"))
```


## Assessment Part 1: Data Import

In this part of the assessment, you will answer several multiple choice
questions that review the concepts of data import. You can answer these
questions without using R, although you may find it helpful to
experiment with commands in your console.

In the second part of the assessment on the next page, you will import
real datasets and learn more about useful arguments to readr functions.
The second part of the assessment will require you to program in R.

### **Question 1**

Which of the following is NOT part of the data wrangling process?

**Answer:** *Checking correlations between your variables*

### **Question 2**

Which files could be opened in a basic text editor?

**Answer:** *data.txt* *data.csv* *data.tsv*

### **Question 3**

You want to analyze a file containing race finish times for a recent
marathon. You open the file in a basic text editor and see lines that
look like the following:

    initials,state,age,time
    vib,MA,61,6:01
    adc,TX,45,5:45
    kme,CT,50,4:19

**Answer:** *A comma-delimited file with a header*

### **Question 4**

Assume the following is the full path to the directory that a student
wants to use as their working directory in R:
"/Users/student/Documents/projects/"

Which of the following lines of code CANNOT set the working directory to
the desired "projects" directory?

**Answer:** *setwd(/Users/student/Documents/projects/)*

### **Question 5**

We want to copy the "murders.csv" file from the dslabs package into an
existing folder "data", which is located in our HarvardX-Wrangling
projects folder. We first enter the code below into our RStudio console.

    > getwd()
    [1] "C:/Users/UNIVERSITY/Documents/Analyses/HarvardX-Wrangling"
    > filename <- "murders.csv"
    > path <- system.file("extdata", package = "dslabs")

Which of the following commands would NOT successfully copy
"murders.csv" into the folder "data"?

**Answer:** *file.copy(file.path(path, "murders.csv"), getwd())*

### **Question 6**

You are not sure whether the murders.csv file has a header row. How
could you check this?

**Answer:** *Open the file in a basic text editor.* *In the RStudio
"Files" pane, click on your file, then select "View File".* *Use the
command read_lines (remembering to specify the number of rows with the
n_max argument).*

### **Question 7**

What is one difference between `read_excel()` and `read_xlsx()`?

**Answer:** *`read_excel()` reads both .xls and .xlsx files by
detecting the file format from its extension, while `read_xlsx()` only
reads .xlsx files.*

### **Question 8**

You have a file called "times.txt" that contains race finish times for a
marathon. The first four lines of the file look like this:

    initials,state,age,time
    vib,MA,61,6:01
    adc,TX,45,5:45
    kme,CT,50,4:19

Which line of code will NOT produce a tibble with column names
"initials", "state", "age", and "time"?

**Answer:** *race_times \<- read.csv("times.txt")*

### **Question 9**

You also have access to marathon finish times in the form of an Excel
document named "times.xlsx". In the Excel document, different sheets
contain race information for different years. The first sheet is named
"2015", the second is named "2016", and the third is named "2017".

Which line of code will NOT import the data contained in the "2016" tab
of this Excel sheet?

**Answer:** *times_2016 \<- read_xlsx("times.xlsx", sheet = "2")*

### **Question 10**

You have a comma-separated values file that contains the initials, home
states, ages, and race finish times for marathon runners. The runners'
initials contain three characters for the runners' first, middle, and
last names (for example, "KME").

You read in the file using the following code.

    race_times <- read.csv(“times.csv”)

What is the data type of the initials in the object `race_times`?

**Answer:** *factors* Nota:*In previous versions of R, this was true,
but is not any more. read.csv() no longer automatically converts
characters to factors. If you want to read in character columns as
factors, you can supply the argument stringsAsFactors = T.*

### **Question 11**

Which of the following is NOT a real difference between the readr import
functions and the base R import functions?

**Answer:** *The base R import functions can read .csv files, but
cannot read files with other delimiters, such as .tsv files, or
fixed-width files.*

### **Question 12**

You read in a file containing runner information and marathon finish
times using the following code.

    race_times <- read.csv(“times.csv”, stringsAsFactors = F)

What is the class of the object `race_times`?

**Answer:** *data frame*

### **Question 13**

Select the answer choice that summarizes all of the actions that the
following lines of code can perform. Please note that the url below is
an example and does not lead to data.

      url <- "https://raw.githubusercontent.com/MyUserName/MyProject/master/MyData.csv "
    dat <- read_csv(url)
    download.file(url, "MyData.csv")

**Answer:** *Create a tibble in R called dat that contains the
information contained in the csv file stored on Github. Download the csv
file to the working directory and name the downloaded file
"MyData.csv".*

# Assessment Part 2: Data Import

In this part of the assessment, you will import real datasets and learn
more about useful arguments to readr functions. You will encounter
common issues that arise when importing raw data. This part of the
assessment will require you to program in R.

Use the readr package in the tidyverse library:

```{r}
library(tidyverse)
```

### **Question 14**

Inspect the file at the following URL:

<https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data>

Which **readr** function should be used to import this file?

**Answer:** `read_csv()`

### **Question 15**

Check the documentation for the readr function you chose in the previous
question to learn about its arguments. Determine which arguments you
need to the file from the previous question:

```{r}
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
```

Does this file have a header row? Does the readr function you chose need
any additional arguments to import the data correctly?

**Answer:** *No, there is no header. The col_names=FALSE argument is necessary.*

### **Question 16**

Inspect the imported data from the previous question.

```{r}
d_q16 <- read_csv(url, col_names = FALSE)

```

How many rows are in the dataset? *569*

How many columns are in the dataset? *32*

# Assessment Part 1: Reshaping Data

Part 1 consists of 8 questions are conceptual questions about tidy data and reshaping data. They do not necessarily require R, but you may benefit from checking your work on the console.

Part 2 consists of 7 questions which require you to write code in R to apply the new concepts about tidy data and reshaping data.

### **Question 1**

A collaborator sends you a file containing data for three years of average race finish times.

```
age_group,2015,2016,2017
20,3:46,3:22,3:50
30,3:50,3:43,4:43
40,4:39,3:49,4:51
50,4:48,4:59,5:01
```
Are these data considered “tidy” in R? Why or why not?

**Answer:** *No. These data are not considered “tidy” because the variable “year” is stored in the header.*

### **Question 2**

Below are four versions of the same dataset. Which one is in a tidy format?


**Answer:**
```
state      abb region  population total
Alabama     AL	South	4779736	  135
Alaska      AK   West 	710231	  19
Arizona     AZ   West	6392017   232
Arkansas    AR  South	2915918	  93
California  CA   West   37253956  1257
Colorado    CO   West	5029196	  65
```

### **Question 3**

Your file called “times.csv” has age groups and average race finish times for three years of marathons.

```
age_group,2015,2016,2017
20,3:46,3:22,3:50
30,3:50,3:43,4:43
40,4:39,3:49,4:51
50,4:48,4:59,5:01
```
You read in the data file using the following command.

```
d <- read_csv("times.csv")
```

**Answer:**    
```
  tidy_data <- d %>%
    gather(year, time, `2015`:`2017`)
```

### **Question 4**

You have a dataset on U.S. contagious diseases, but it is in the following wide format:

```
> head(dat_wide)
state year population HepatitisA Mumps Polio Rubella
Alabama 1990    4040587      86	   19    76    1
Alabama 1991    4066003      39	   14    65    0
Alabama 1992    4097169      35	   12    24    0
Alabama 1993    4133242      40	   22    67    0
Alabama 1994    4173361      72	   12    39    0
Alabama 1995    4216645      75     2    38    0
```

You want to transform this into a tidy dataset, with each row representing an observation of the incidence of each specific disease (as shown below):

```
> head(dat_tidy)
state   year  population  disease  count
Alabama 1990	4040587 HepatitisA	86
Alabama 1991	4066003 HepatitisA	39
Alabama 1992	4097169 HepatitisA	35
Alabama 1993	4133242 HepatitisA	40
Alabama 1994	4173361 HepatitisA	72
Alabama 1995	4216645 HepatitisA	75
```

Which of the following commands would achieve this transformation to tidy the data?

**Answer:**   
```
dat_tidy <- dat_wide %>%
    gather(key = disease, value = count, HepatitisA:Rubella)
```

### **Question 5**

You have successfully formatted marathon finish times into a tidy object called tidy_data. The first few lines are shown below.

```
age_group year   time
20        2015   03:46
30        2015   03:50
40        2015   04:39
50        2015   04:48
20        2016   03:22
```

Select the code that converts these data back to the wide format, where each year has a separate column.

**Answer:**   
*tidy_data %>% spread(year, time)*

### **Question 6**

You have the following dataset:
```
    > head(dat)
state   abb region    	var   people
Alabama  AL  South population 4779736
Alabama  AL  South  	total 	  135
Alaska   AK   West population  710231
Alaska   AK   West  	total  	   19
Arizona  AZ   West population 6392017
Arizona  AZ   West  	total 	  232
  ```
You would like to transform it into a dataset where population and total are each their own column (shown below):

```
state      abb region population total
Alabama     AL  South	4779736   135
Alaska      AK   West 710231    19
Arizona     AZ   West	6392017   232
Arkansas    AR  South	2915918    93
California  CA   West  37253956  1257
Colorado    CO   West	5029196	   65
```
Which code would best accomplish this?

**Answer:**   
*dat_tidy <- dat %>% spread(key = var, value = people)*

### **Question 7**

A collaborator sends you a file containing data for two years of average race finish times, "times.csv":

```
age_group,2015_time,2015_participants,2016_time,2016_participants
20,3:46,54,3:22,62
30,3:50,60,3:43,58
40,4:39,29,3:49,33
50,4:48,10,4:59,14
```
You read in the data file:

```
d <- read_csv("times.csv")

```
Which of the answers below best makes the data tidy?


**Answer:**   
```
  tidy_data <- d %>%
    gather(key = “key”, value = “value”, -age_group) %>%
    separate(col = key, into = c(“year”, “variable_name”), sep = “_”) %>% 
    spread(key = variable_name, value = value)
```

### **Question 8**

You are in the process of tidying some data on heights, hand length, and wingspan for basketball players in the draft. Currently, you have the following:

```
    > head(stats)
key               value
allen_height      75
allen_hand_length 8.25
allen_wingspan	  79.25
bamba_height      83.25
bamba_hand_length 9.75
bamba_wingspan    94
 ``` 
Select all of the correct commands below that would turn this data into a “tidy” format with columns "height", "hand_length" and "wingspan".

**Answer:**

```
 tidy_data <- stats %>%
    separate(col = key, into = c("player", "variable_name"), sep = "_", extra = "merge") %>% 
    spread(key = variable_name, value = value)
```

# Assessment Part 2: Reshaping Data

Use the following libraries for these questions:


```{r}
library(tidyverse)
library(dslabs)

```

### **Question 9**

Examine the built-in dataset `co2.` This dataset comes with base R, not **dslabs** - just type `co2` to access the dataset.

Is `co2` tidy? Why or why not?

```{r}
head(co2)
```
**Answer:**
*co2 is not tidy: to be tidy we would have to wrangle it to have three columns (year, month and value), and then each co2 observation would have a row.*

### **Question 10**

Run the following command to define the co2_wide object:

```{r}
co2_wide <- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) %>% 
      setNames(1:12) %>% 
    mutate(year = as.character(1959:1997))

```

Use the `gather()` function to make this dataset tidy. Call the column with the CO2 measurements `co2` and call the month column `month.` Name the resulting object `co2_tidy.`

Which code would return the correct tidy format?

**Answer:**
```{r}
co2_tidy <- gather(co2_wide,month,co2,-year)
```

### **Question 11**

Use co2_tidy to plot CO2 versus month with a different curve for each year:

```{r}
co2_tidy %>% ggplot(aes(as.numeric(month), co2, color = year)) + geom_line()
```

      


    
What can be concluded from this plot?

**Answer:**
*CO2 concentrations are highest around May and the yearly average increased from 1959 to 1997.*


### **Question 12**

Load the `admissions` dataset from **dslabs**, which contains college admission information for men and women across six majors, and remove the `applicants` percentage column:

```{r}
library(dslabs)
data(admissions)
dat <- admissions %>% select(-applicants)
```
Your goal is to get the data in the shape that has one row for each major, like this:

```
major  men   women
A      62    82		
B      63    68		
C      37    34		
D      33    35		
E      28    24		
F       6     7	
```
Which command could help you to wrangle the data into the desired format?
      
**Answer:**
```{r}
dat_tidy <- spread(dat, gender, admitted)
```

### **Question 13**

Now use the `admissions` dataset to create the object tmp, which has columns `major`, `gender`, `key` and `value`:


```{r}
tmp <- gather(admissions, key, value, admitted:applicants)
tmp
```
Combine the `key` and `gender` and create a new column called `column_name` to get a variable with the following values: `admitted_men`, `admitted_women`, `applicants_men` and `applicants_women.` Save the new data as `tmp2`.

Which command could help you to wrangle the data into the desired format?

**Answer:**
```{r}
tmp2 <- unite(tmp, column_name, c(key, gender))
```

### **Question 14**

Which function can reshape `tmp2` to a table with six rows and five columns named `major`, `admitted_men`, `admitted_women`, `applicants_men` and `applicants_women`?

**Answer:**
```{r}
spread(tmp2,column_name,value)
```

# Assessment: Combining Tables

### **Question 1**

You have created data frames `tab1` and `tab2` of state population and election data, similar to our module videos:

```
      > tab1
state   	     population
Alabama             4779736
Alaska     	         710231
Arizona    	        6392017
Delaware     	     897934
District of Columbia 601723

> tab2
state  electoral_votes
Alabama      9
Alaska       3
Arizona     11
California  55
Colorado     9
Connecticut  7

> dim(tab1)
[1] 5 2

> dim(tab2)
[1] 6 2
   ``` 
What are the dimensions of the table dat, created by the following command?

      
```dat <- left_join(tab1, tab2, by = “state”)```

**Answer:**
*5 rows by 3 columns*

### **Question 2**

We are still using the `tab1` and `tab2` tables shown in question 1. What join command would create a new table “dat” with three rows and two columns?

**Answer:**
*dat <- semi_join(tab1, tab2, by = “state”)*

### **Question 3**

Which of the following are real differences between the join and bind functions?

**Answer:**
*Binding functions combine by position, while join functions match by variables.*
*Joining functions can join datasets of different dimensions, but the bind functions must match on the appropriate dimension (either same row or column numbers).*
*Bind functions can combine both vectors and dataframes, while join functions work for only for dataframes.*

### **Question 4**

We have two simple tables, shown below, with columns x and y:

```
> df1
 x     y    
 a     a    
 b     a    

> df2
 x     y    
 a     a    
 a     b  
 ```
 
Which command would result in the following table?

```
> final
 x     y    
 b     a   
 ```
 
 **Answer:**
 
```
final <- setdiff(df1, df2)
```

**Introduction to Questions 5-7**

Install and load the Lahman library. This library contains a variety of datasets related to US professional baseball. We will use this library for the next few questions and will discuss it more extensively in the Regression course. For now, focus on wrangling the data rather than understanding the statistics.

The Batting data frame contains the offensive statistics for all baseball players over several seasons.  Filter this data frame to define top as the top 10 home run (HR) hitters in 2016:

```{r}
install.packages("Lahman")
library(Lahman)
top <- Batting %>% 
  filter(yearID == 2016) %>%
  arrange(desc(HR)) %>%    # arrange by descending HR count
  slice(1:10)    # take entries 1-10
top %>% as_tibble()

```

Also Inspect the Master data frame, which has demographic information for all players:

```{r}
Master %>% as_tibble()
```
### **Question 5**

Use the correct `join` or `bind` function to create a combined table of the names and statistics of the top 10 home run (HR) hitters for 2016. This table should have the player ID, first name, last name, and number of HR for the top 10 players. Name this data frame top_names.

Identify the join or bind that fills the blank in this code to create the correct table:

```{r}
top_names <- top %>% left_join(Master, by="playerID") %>%
    select(playerID, nameFirst, nameLast, HR)
top_names
```
Which bind or join function fills the blank to generate the correct table?

 **Answer:**
 
```
left_join(Master)
```

### **Question 6**

Inspect the `Salaries` data frame. Filter this data frame to the 2016 salaries, then use the correct bind join function to add a salary column to the `top_names` data frame from the previous question. Name the new data frame `top_salary.` Use this code framework:

```{r}
top_salary <- Salaries %>% filter(yearID == 2016) %>%
  right_join(top_names) %>%
  select(nameFirst, nameLast, teamID, HR, salary)
```
Which bind or join function fills the blank to generate the correct table?

**Answer:**
 
```
right_join(Master)
```
### **Question 7**

Inspect the `AwardsPlayers` table. Filter awards to include only the year 2016.

How many players from the top 10 home run hitters won at least one award in 2016?

```{r}
AwardsPlayers %>% filter(yearID == 2016) %>% semi_join(top_names, by="playerID") %>%  distinct(playerID) %>% count()
```
How many players won an award in 2016 but were not one of the top 10 home run hitters in 2016?

```{r}
AwardsPlayers %>% filter(yearID == 2016) %>% anti_join(top_names, by="playerID") %>% distinct(playerID) %>% count()

```

# Assessment:  Web Scraping

### **Introduction: Questions 1-3**

Load the following web page, which contains information about Major League Baseball payrolls, into R: [https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm](https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm) 

```{r}
library(rvest)
url <- "https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm"
h <- read_html(url)
```
We learned that tables in html are associated with the table node.  Use the html_nodes() function and the table node type to extract the first table. Store it in an object nodes:

```{r}
nodes <- html_nodes(h, "table")
```
The html_nodes() function returns a list of objects of class xml_node. We can see the content of each one using, for example, the html_text() function. You can see the content for an arbitrarily picked component like this:

```{r}
html_text(nodes[[8]])
```
If the content of this object is an html table, we can use the html_table() function to convert it to a data frame:

```{r}
html_table(nodes[[8]])

```
### **Question 1**

Many tables on this page are team payroll tables, with columns for rank, team, and one or more money values.

Convert the first four tables in nodes to data frames and inspect them. (Note that "parsing errors" and/or "empty tables" still count towards the table index!)

Which of the first four nodes are tables of team payroll?

**Answer:**

*Table 2, Table 3 and Table 4*

```{r}
html_table(nodes[1:4])
```

### **Question 2**

For the last 3 components of nodes, which of the following are true? (Check all correct answers.)

**Answer:**

*All three entries are tables. *
*The last entry shows the average across all teams through time, not payroll per team.*

```{r}
html_table(tail(nodes,n=3))
```
### **Question 3**

Create a table called `tab_1` using entry 10 of `nodes.` Create a table called `tab_2` using entry 19 of `nodes.`

Note that the column names should be `c("Team", "Payroll", "Average")`. You can see that these column names are actually in the first data row of each table, and that `tab_1` has an extra first column `No.` that should be removed so that the column names for both tables match.

Remove the extra column in `tab_1`, remove the first row of each dataset, and change the column names for each table to `c("Team", "Payroll", "Average")`. Use a `full_join()` by the Team to combine these two tables.

How many rows are in the joined data table?

**Answer:** *58*

```{r}
tab_1 <- html_table(nodes[[10]],header = TRUE)[,-1] 
tab_2 <- html_table(nodes[[19]],header = TRUE)
tab_1 %>% full_join(tab_2,"Team")

```
### **Introduction: Questions 4 and 5**

The Wikipedia page on [opinion polling for the Brexit referendum](https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054) , in which the United Kingdom voted to leave the European Union in June 2016, contains several tables. One table contains the results of all polls regarding the referendum over 2016:

Use the **rvest** library to read the HTML from this Wikipedia page (make sure to copy both lines of the URL):

```{r}
library(rvest)
library(tidyverse)
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
```

### **Question 4**

Assign `tab` to be the html nodes of the "table" class.

How many tables are in this Wikipedia page?

**Answer:** *41*

```{r}
h <- read_html(url)
tab <- html_nodes(h, "table")
tab
```

### **Question 5**

Inspect the first several html tables using `html_table()` with the argument fill=TRUE (you can read about this argument in the documentation). Find the first table that has 9 columns with the first column named "Date(s) conducted".

What is the first table number to have 9 columns where the first column is named "Date(s) conducted"?

**Answer:** *6*

```{r, include=FALSE}
html_table(tab[1:9], fill = TRUE)
```


```{r}
html_table(tab[[6]], fill = TRUE)
```
# Assessment: String Processing Part 1

### **Question 1**

Which of the following is NOT an application of string parsing?

**Answer:**
*Formatting numbers and characters so they can easily be displayed in deliverables like papers and presentations.*

### **Question 2**

Which of the following commands would not give you an error in R?

**Answer:**
*cat(" LeBron James is 6’8\" ")*

### **Question 3**

Which of the following are advantages of the stringr package over string processing functions in base R? Select all that apply.

**Answer:**
*Functions in stringr all start with “str_”, which makes them easy to look up using autocomplete.*
*Stringr functions work better with pipes.*
*The order of arguments is more consistent in stringr functions than in base R.*

### **Question 4**

You have a data frame of monthly sales and profits in R:

```
      > head(dat)
# A tibble: 5 x 3
Month     Sales     Profit 
<chr>     <chr>     <chr>  
January   $128,568  $16,234
February  $109,523  $12,876
March     $115,468  $17,920
April     $122,274  $15,825
May       $117,921  $15,437
  ```  
Which of the following commands could convert the sales and profits columns to numeric? Select all that apply.

**Answer:**
*dat %>% mutate_at(2:3, parse_number)*
*dat %>% mutate_at(2:3, funs(str_replace_all(., c("\\$|,"), ""))) %>% mutate_at(2:3, as.numeric)*


# Assessment: String Processing Part 2

### **Question 1**

In the video, we use the function not_inches to identify heights that were incorrectly entered

```{r}
not_inches <- function(x, smallest = 50, tallest = 84) {
  inches <- suppressWarnings(as.numeric(x))
  ind <- is.na(inches) | inches < smallest | inches > tallest 
  ind
}
```
In this function, what TWO types of values are identified as not being correctly formatted in inches?

**Answer:**
*Values that result in NA’s when converted to numeric*
*Values less than 50 inches or greater than 84 inches*

### **Question 2**

Which of the following arguments, when passed to the function `not_inches()`, would return the vector `c(FALSE)`?

**Answer:** *c(70)*
```{r}
not_inches(c(70))
```
### **Question 3**

Our function `not_inches()` returns the object `ind.` Which answer correctly describes ind?

**Answer:** 

*`ind` is a logical vector of TRUE and FALSE, equal in length to the vector `x` (in the arguments list). TRUE indicates that a height entry is incorrectly formatted.*

### **Question 4**

Given the following code

```
      > s
[1] "70"       "5 ft"     "4'11"     ""         "."        "Six feet"
```
What pattern vector yields the following result?

```
      str_view_all(s, pattern)
70
5 ft
4’11
.
Six feet    
```

**Answer:** 

*pattern <- "\\d|ft"*

### **Question 5**

You enter the following set of commands into your R console. What is your printed result?

 **Answer:** *TRUE TRUE TRUE FALSE*    

```{r}
animals <- c("cat", "puppy", "Moose", "MONKEY")
pattern <- "[a-z]"
str_detect(animals, pattern)
```
### **Question 6**

You enter the following set of commands into your R console. What is your printed result?

**Answer:** *FALSE FALSE FALSE TRUE*    
```{r}
      animals <- c("cat", "puppy", "Moose", "MONKEY")
pattern <- "[A-Z]$"
str_detect(animals, pattern)
```

### **Question 7**

You enter the following set of commands into your R console. What is your printed result?

**Answer:** *FALSE FALSE FALSE TRUE* 4 or 5 lowercase letters in a row
```{r}
animals <- c("cat", "puppy", "Moose","MONKEY")
pattern <- "[a-z]{4,5}"
str_detect(animals, pattern)
```
### **Question 8**

Given the following code:

```{r}
animals <- c("moose", "monkey", "meerkat", "mountain lion")
```

Which TWO “pattern” vectors would yield the following result?

```
> str_detect(animals, pattern)
[1] TRUE TRUE TRUE TRUE
```
**Answer:**
```{r}
pattern <- "mo*"
pattern <- "mo?"
str_detect(animals, pattern)
```

### **Question 9**

You are working on some data from different universities. You have the following vector:

```
schools
[1] "U. Kentucky"                 "Univ New Hampshire"          "Univ. of Massachusetts"      "University Georgia"         
[5] "U California"                "California State University"
```
You want to clean this data to match the full names of each university:

```
final
[1] "University of Kentucky"      "University of New Hampshire" "University of Massachusetts" "University of Georgia"         
[5] "University of California"    "California State University"
```
What of the following commands could accomplish this?

**Answer:**

```
schools %>% 
    str_replace("^Univ\\.?\\s|^U\\.?\\s", "University ") %>% 
    str_replace("^University of |^University ", "University of ")
```

### **Question 10**

Rather than using the pattern_with_groups vector from the video, you accidentally write in the following code:

```{r}
problems <- c("5.3", "5,5", "6 1", "5 .11", "5, 12")
pattern_with_groups <- "^([4-7])[,\\.](\\d*)$"
str_replace(problems, pattern_with_groups, "\\1'\\2")
```
What is your result?

**Answer:** *[1] "5'3" "5'5" "6 1" "5 .11" "5, 12"*

### **Question 11**

You notice your mistake and correct your pattern regex to the following

```{r}
problems <- c("5.3", "5,5", "6 1", "5 .11", "5, 12")
pattern_with_groups <- "^([4-7])[,\\.\\s](\\d*)$"
str_replace(problems, pattern_with_groups, "\\1'\\2")
```

What is your result? 

**Answer:** *[1] "5'3"   "5'5"   "6'1"   "5 .11" "5, 12"*

### **Question 12**

In our example, we use the following code to detect height entries that do not match our pattern of x’y”:

```{r}
converted <- problems %>% 
  str_replace("feet|foot|ft", "'") %>% 
  str_replace("inches|in|''|\"", "") %>% 
  str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2")

pattern <- "^[4-7]\\s*'\\s*\\d{1,2}$"
index <- str_detect(converted, pattern)
converted[!index]
```
Which answer best describes the differences between the regex string we use as an argument in `str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2")` and the regex string in pattern <- `"^[4-7]\\s*'\\s*\\d{1,2}$"`?

**Answer:**
*The regex used in str_replace() looks for either a comma, period or space between the feet and inches digits, while the pattern regex just looks for an apostrophe; the regex in str_replace allows for none or more digits to be entered as inches, while the pattern regex only allows for one or two dig*

### **Question 13**

You notice a few entries that are not being properly converted using your `str_replace()` and `str_detect()` code:

```{r}
yes <- c("5 feet 7inches", "5 7")
no <- c("5ft 9 inches", "5 ft 9 inches")
s <- c(yes, no)

converted <- s %>% 
  str_replace("feet|foot|ft", "'") %>% 
  str_replace("inches|in|''|\"", "") %>% 
  str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2")

pattern <- "^[4-7]\\s*'\\s*\\d{1,2}$"
str_detect(converted, pattern)
```

It seems like the problem may be due to spaces around the words feet|foot|ft and inches|in. What is another way you could fix this problem?

**Answer:**
```{r}
converted <- s %>% 
    str_replace("\\s*(feet|foot|ft)\\s*", "'") %>% 
    str_replace("\\s*(inches|in|''|\")\\s*", "") %>% 
    str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2")
```

# Assessment Part 1: String Processing Part 3

### **Question 1**

You have the following table, schedule:

```{r}
day <- c("monday","tuesday")
staff <- c("Mandy, Chris and Laura", "Steve, Ruth and Frank")

schedule <- data.frame(day,staff)
```
```
>schedule
day		staff
Monday		Mandy, Chris and Laura
Tuesday		Steve, Ruth and Frank
```
You want to turn this into a more useful data frame.

Which two commands would properly split the text in the “staff” column into each individual name? Select ALL that apply.


**Answer:**
```{r}
str_split(schedule$staff, ",\\s|\\sand\\s")
str_split(schedule$staff, ", | and ")
```

### **Question 2**

You have the following table, schedule:

```
> schedule
day         staff
Monday   	Mandy, Chris and Laura
Tuesday 	Steve, Ruth and Frank

```

What code would successfully turn your “Schedule” table into the following tidy table?

```
> tidy
day     staff
<chr>   <chr>
Monday  Mandy
Monday  Chris
Monday  Laura
Tuesday Steve
Tuesday Ruth 
Tuesday Frank
```


**Answer:**
```{r}
tidy <-  schedule %>% 
  mutate(staff = str_split(staff, ", | and ")) %>% 
  unnest()
        
```

### **Question 3**

Using the gapminder data, you want to recode countries longer than 12 letters in the region “Middle Africa” to their abbreviations in a new column, “country_short”. Which code would accomplish this?

**Answer:**

```{r}
library(dslabs)
data("gapminder")
 dat <- gapminder %>% filter(region == "Middle Africa") %>% 
  mutate(country_short = recode(country, 
                                "Central African Republic" = "CAR", 
                                "Congo, Dem. Rep." = "DRC",
                                "Equatorial Guinea" = "Eq. Guinea"))
```


# Assessment Part 2: String Processing Part 3

Import raw Brexit referendum polling data from Wikipedia:

```{r}
library(rvest)
library(tidyverse)
library(stringr)
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
tab <- read_html(url) %>% html_nodes("table")
polls <- tab[[6]] %>% html_table(fill = TRUE)
```
You will use a variety of string processing techniques learned in this section to reformat these data.


### **Question 4**

Some rows in this table do not contain polls. You can identify these by the lack of the percent sign (%) in the Remain column.

Update `polls` by changing the column names to `c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes")` and only keeping rows that have a percent sign (%) in the `remain` column.

How many rows remain in the polls data frame?

**Answer:**
```{r}
polls <-  polls[-1,] %>% setNames(c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes")) %>%  filter(str_detect(.$remain, "\\%"))

polls %>% nrow() 
```
### **Question 5**

The `remain` and `leave` columns are both given in the format "48.1%": percentages out of 100% with a percent symbol.

Which of these commands converts the remain vector to a proportion between 0 and 1?

**Answer:**
```{r}
as.numeric(str_replace(polls$remain, "%", ""))/100
parse_number(polls$remain)/100
```
### **Question 6**

The undecided column has some "N/A" values. These "N/A"s are only present when the remain and leave columns total 100%, so they should actually be zeros.

Use a function from **stringr** to convert "N/A" in the undecided column to 0. The format of your command should be `function_name(polls$undecided, "arg1", "arg2")`.

What function replaces function_name?
What argument replaces arg1?
What argument replaces arg2?

**Answer:**
```{r}
str_replace(polls$undecided, "N/A", "0")
```


### **Question 7**

The dates column contains the range of dates over which the poll was conducted. The format is "8-10 Jan" where the poll had a start date of 2016-01-08 and end date of 2016-01-10. Some polls go across month boundaries (16 May-12 June).

The end date of the poll will always be one or two digits, followed by a space, followed by the month as one or more letters (either capital or lowercase). In these data, all month abbreviations or names have 3, 4 or 5 letters.

Write a regular expression to extract the end day and month from dates. Insert it into the skeleton code below:

**Answer:**
```{r}
pattern_opt <- c("\\d+\\s[a-zA-Z]+","[0-9]+\\s[a-zA-Z]+","\\d{1,2}\\s[a-zA-Z]+","\\d+\\s[a-zA-Z]{3,5}")
temp <- str_extract_all(polls$dates, "\\d+\\s[a-zA-Z]+")
end_date <- sapply(temp, function(x) x[length(x)]) # take last element (handles polls that cross month boundaries)
```

# Assessment Part 1: Dates, Times, and Text Mining

This assessment reviews several concepts about dates, times, and text mining. In part 1 on this page, you will practice extracting and manipulating dates in real datasets. In part 2 on the next page, you will walk through a sentiment analysis of a novel using steps covered in the previous section.

Use the following libraries and options for coding questions:
```{r}
library(dslabs)
library(lubridate)
options(digits = 3)    # 3 significant digits
```

IMPORTANT: Some of these exercises use dslabs datasets that were added in a July 2019 update. Make sure your package is up to date with the command install.packages("dslabs").

### **Question 1**

Which of the following is the standard ISO 8601 format for dates?

**Answer:**
*YYYY-MM-DD*

### **Question 2**

Which of the following commands could convert this string into the correct date format?

**Answer:**
*It is impossible to know which format is correct without additional information.*

### **Question 3**

Load the brexit_polls data frame from dslabs:

```{r}
data(brexit_polls)
head(brexit_polls)
```

How many polls had a start date (`startdate`) in April (month number 4)?
**Answer:**
```{r}
brexit_polls %>% mutate(month=month(startdate)) %>% filter(month==4)
```

Use the `round_date()` function on the `enddate` column with the argument unit="week". How many polls ended the week of 2016-06-12?
**Answer:**
```{r}
brexit_polls %>% mutate(weekenddate=round_date(enddate,unit = "week")) %>% filter(weekenddate=='2016-06-12')
```

### **Question 4**
Use the `weekdays()` function from lubridate to determine the weekday on which each poll ended (enddate).
On which weekday did the greatest number of polls end?

**Answer:**
```{r}
brexit_polls %>% mutate(weekday=weekdays(enddate)) %>% group_by(weekday) %>% count()
```
### **Question 5**
Load the movielens data frame from dslabs.
```{r}
data(movielens)
movielens %>% head()
```

This data frame contains a set of about 100,000 movie reviews. The `timestamp` column contains the review date as the number of seconds since 1970-01-01 (epoch time).

Convert the timestamp column to dates using the **lubridate** `as_datetime()` function.

```{r}
movielens %>% mutate(date=as_datetime(timestamp))

```


Which year had the most movie reviews?
**Answer:**
```{r}

movielens %>% mutate(date=as_datetime(timestamp),yr=year(date)) %>%  group_by(yr) %>% count()  %>% arrange(desc(n))

```
Which hour of the day had the most movie reviews?
**Answer:**
```{r}

movielens %>% mutate(date=as_datetime(timestamp),hr=hour(date)) %>%  group_by(hr) %>% count() %>% arrange(desc(n))

```
# Assessment Part 2: Dates, Times, and Text Mining

In this part of the assessment, you will walk through a basic text mining and sentiment analysis task.

Project Gutenberg is a digital archive of public domain books. The R package gutenbergr facilitates the importation of these texts into R. We will combine this with the tidyverse and tidytext libraries to practice text mining.

Use these libraries and options:

```{r, warning=FALSE}
library(tidyverse)
library(gutenbergr)
library(tidytext)
options(digits = 3)
```
You can see the books and documents available in gutenbergr like this:

```{r}
mtgu <- gutenberg_metadata
```

### **Question 6**

Use `str_detect()` to find the ID of the novel Pride and Prejudice.

How many different ID numbers are returned?
**Answer:**

```{r}
mtgu %>% count(str_detect(.$title,pattern = "Pride and Prejudice"))
```

### **Question 7**

Notice that there are several versions of the book. The `gutenberg_works()` function filters this table to remove replicates and include only English language works. Use this function to find the ID for Pride and Prejudice.

What is the correct ID number?
**Answer:**

```{r}
PRgu <- gutenberg_works(languages = "en")
gutenberg_works(languages = "en") %>% filter(str_detect(.$title, pattern = "Pride and Prejudice")==TRUE)
```
### **Question 8**
Use the `gutenberg_download()` function to download the text for Pride and Prejudice. Use the `tidytext` package to create a tidy table with all the words in the text. Save this object as words.

How many words are present in the book?
**Answer:**

```{r}
book_pri_pre <- gutenberg_download(gutenberg_id = 1342) %>% select(text)
words <- book_pri_pre %>% unnest_tokens(word, text) #you should specifiet the column name from the object
count(words)
```
### **Question 9**

Remove stop words from the words object. Recall that stop words are defined in the `stop_words` data frame from the `tidytext` package.

How many words remain?
**Answer:**
```{r}
words_wnsp <- words %>% filter(!word %in% stop_words$word)
count(words_wnsp)
```
### **Question 10**

After removing stop words, detect and then filter out any token that contains a digit from words.

How many words remain?
**Answer:**
```{r}
words_clean <- words_wnsp %>% filter(!str_detect(.$word, pattern = "\\d"))
count(words_clean)
```

### **Question 11**

Analyze the most frequent words in the novel after removing stop words and tokens with digits.

How many words appear more than 100 times in the book?
What is the most common word in the book?
How many times does that most common word appear?
**Answer:**

```{r}
count(words_clean %>% group_by(word) %>%  count() %>% filter(n>100) %>% ungroup())

words_clean %>% group_by(word) %>%  count() %>% arrange(desc(n)) %>% ungroup() %>%  filter(row_number()==1)

```
### **Question 12**

Define the `afinn` lexicon:

```{r}
afinn <- get_sentiments("afinn")
```
Note that this command will trigger a question in the R Console asking if you want to download the AFINN lexicon. Press 1 to select "Yes" (if using RStudio, enter this in the Console tab).

Use this `afinn` lexicon to assign sentiment values to `words.` Keep only words that are present in both `words` and the `afinn` lexicon. Save this data frame as `afinn_sentiments`.

How many elements of words have sentiments in the `afinn` lexicon?
What proportion of words in `afinn_sentiments` have a positive value?
How many elements of `afinn_sentiments` have a value of 4?

**Answer:**

```{r}
afinn_sentiments <- words_clean %>% inner_join(afinn,by = "word")
nrow(afinn_sentiments)

(afinn_sentiments %>% filter(value>0) %>% count())/count(afinn_sentiments)

afinn_sentiments %>% filter(value==4) %>% count()

```

